llama3.2:3b:
  num_predict: 100
  temperature": 0
all-minilm:
